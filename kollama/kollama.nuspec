<?xml version="1.0" encoding="utf-8"?>
<package xmlns="http://schemas.microsoft.com/packaging/2015/06/nuspec.xsd">
  <metadata>
    <!-- == PACKAGE SPECIFIC SECTION == -->
    <!-- This section is about this package, although id and version have ties back to the software -->
    <!-- id is lowercase and if you want a good separator for words, use '-', not '.'. Dots are only acceptable as suffixes for certain types of packages, e.g. .install, .portable, .extension, .template -->
    <!-- If the software is cross-platform, attempt to use the same id as the debian/rpm package(s) if possible. -->
    <id>kollama</id>
    <!-- version should MATCH as closely as possible with the underlying software -->
    <!-- Is the version a prerelease of a version? https://docs.nuget.org/create/versioning#creating-prerelease-packages -->
    <!-- Note that unstable versions like 0.0.1 can be considered a released version, but it's possible that one can release a 0.0.1-beta before you release a 0.0.1 version. If the version number is final, that is considered a released version and not a prerelease. -->
    <version>0.7.1</version>
    <!-- <packageSourceUrl>Where is this Chocolatey package located (think GitHub)? packageSourceUrl is highly recommended for the community feed</packageSourceUrl>-->
    <!-- owners is a poor name for maintainers of the package. It sticks around by this name for compatibility reasons. It basically means you. -->
    <owners>LemonNekoGH</owners>
    <!-- ============================== -->

    <!-- == SOFTWARE SPECIFIC SECTION == -->
    <!-- This section is about the software itself -->
    <title>Ollama Operator</title>
    <authors>nekomeowww</authors>
    <!-- projectUrl is required for the community feed -->
    <projectUrl>https://github.com/nekomeowww/ollama-operator</projectUrl>
    <!-- There are a number of CDN Services that can be used for hosting the Icon for a package. More information can be found here: https://docs.chocolatey.org/en-us/create/create-packages#package-icon-guidelines -->
    <!-- Here is an example using Githack -->
    <iconUrl>https://raw.githubusercontent.com/nekomeowww/ollama-operator/v0.7.1/docs/public/logo.png</iconUrl>
    <!-- <copyright>Year Software Vendor</copyright> -->
    <!-- If there is a license Url available, it is required for the community feed -->
    <licenseUrl>https://github.com/nekomeowww/ollama-operator/blob/main/LICENSE</licenseUrl>
    <requireLicenseAcceptance>false</requireLicenseAcceptance>
    <projectSourceUrl>https://github.com/nekomeowww/ollama-operator</projectSourceUrl>
    <docsUrl>https://ollama-operator.ayaka.io/pages/en/</docsUrl>
    <!--<mailingListUrl></mailingListUrl>-->
    <bugTrackerUrl>https://github.com/nekomeowww/ollama-operator/issues</bugTrackerUrl>
    <tags>kollama kubernetes kubernetes-operators ai ollama llm llama llamacpp</tags>
    <summary>Yet another operator for running large language models on Kubernetes with ease. Powered by Ollama! üê´</summary>
    <description>
      While [Ollama](https://github.com/ollama/ollama) is a powerful tool for running large language models locally, and the user experience of CLI is just the same as using Docker CLI, it's not possible yet to replicate the same user experience on Kubernetes, especially when it comes to running multiple models on the same cluster with loads of resources and configurations.
      
      That's where the Ollama Operator kicks in:
      
      - Install the operator on your Kubernetes cluster
      - Apply the needed CRDs
      - Create your models
      - Wait for the models to be fetched and loaded, that's it!
      
      Thanks to the great works of [lama.cpp](https://github.com/ggerganov/llama.cpp), **no more worries about Python environment, CUDA drivers.**
      
      The journey to large language models, AIGC, localized agents, [ü¶úüîó Langchain](https://www.langchain.com/) and more is just a few steps away!
      
      ## Features
      
      - ‚úÖ Abilities to run multiple models on the same cluster.
      - ‚úÖ Compatible with all Ollama models, APIs, and CLI.
      - ‚úÖ Able to run on [general Kubernetes clusters](https://kubernetes.io/), [K3s clusters](https://k3s.io/) (Respberry Pi, TrueNAS SCALE, etc.), [kind](https://kind.sigs.k8s.io/), [minikube](https://minikube.sigs.k8s.io/docs/), etc. You name it!
      - ‚úÖ Easy to install, uninstall, and upgrade.
      - ‚úÖ Pull image once, share across the entire node (just like normal images).
      - ‚úÖ Easy to expose with existing Kubernetes services, ingress, etc.
      - ‚úÖ Doesn't require any additional dependencies, just Kubernetes.
    </description>
    <!-- <releaseNotes>__REPLACE_OR_REMOVE__MarkDown_Okay</releaseNotes> -->
    <!-- =============================== -->

    <!-- Specifying dependencies and version ranges? https://docs.nuget.org/create/versioning#specifying-version-ranges-in-.nuspec-files -->
    <!--<dependencies>
      <dependency id="" version="__MINIMUM_VERSION__" />
      <dependency id="" version="[__EXACT_VERSION__]" />
      <dependency id="" version="[_MIN_VERSION_INCLUSIVE, MAX_VERSION_INCLUSIVE]" />
      <dependency id="" version="[_MIN_VERSION_INCLUSIVE, MAX_VERSION_EXCLUSIVE)" />
      <dependency id="" />
      <dependency id="chocolatey-core.extension" version="1.1.0" />
    </dependencies>-->
    <!-- chocolatey-core.extension - https://community.chocolatey.org/packages/chocolatey-core.extension -->

    <!--<provides>NOT YET IMPLEMENTED</provides>-->
    <!--<conflicts>NOT YET IMPLEMENTED</conflicts>-->
    <!--<replaces>NOT YET IMPLEMENTED</replaces>-->
  </metadata>
  <files>
    <!-- this section controls what actually gets packaged into the Chocolatey package -->
    <file src="tools\**" target="tools" />
  </files>
</package>
